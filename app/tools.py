import os
from dotenv import load_dotenv
from openai import OpenAI
from datetime import datetime
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from sentence_transformers import SentenceTransformer
from collections import Counter
import ast
from langchain_community.embeddings import HuggingFaceEmbeddings

from app.database import SessionLocal, UserHistory
import requests

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SPOONACULAR_API_KEY = os.getenv("SPOONACULAR_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

VECTOR_DB_PATH = "vector_store/recipes"
embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

def get_or_create_vectorstore():
    if os.path.exists(VECTOR_DB_PATH):
        return FAISS.load_local(
            VECTOR_DB_PATH,
            embeddings=embedding_model,
            allow_dangerous_deserialization=True  
            )
    else:
        os.makedirs(VECTOR_DB_PATH, exist_ok=True)
        print("ğŸ†• ë²¡í„° ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        return FAISS.from_documents([], embedding_model)

def build_flexible_recipe_params(profile):
    base_params = {
        "apiKey": SPOONACULAR_API_KEY,
        "number": 5,
        "addRecipeInformation": True
    }

    ingredients = profile.get("ingredients")
    cuisine = profile.get("preferred_cuisine")
    max_time = profile.get("avg_time")

    tried_params = []

    if ingredients and "," in ingredients:
        query_version = ingredients.replace(",", " ")
        tried_params.append({**base_params, "query": query_version})
    if ingredients and cuisine and max_time:
        tried_params.append({**base_params, "includeIngredients": ingredients, "cuisine": cuisine, "maxReadyTime": max_time})
    if ingredients and cuisine:
        tried_params.append({**base_params, "includeIngredients": ingredients, "cuisine": cuisine})
    if ingredients:
        tried_params.append({**base_params, "includeIngredients": ingredients})
    if cuisine:
        tried_params.append({**base_params, "cuisine": cuisine})

    tried_params.append(base_params)

    return tried_params

def get_recipes_from_api(profile):
    for params in build_flexible_recipe_params(profile):
        response = requests.get("https://api.spoonacular.com/recipes/complexSearch", params=params)
        data = response.json()
        if data.get("results"):
            return data["results"]
    return []

def build_recipe_params(user_profile=None):
    params = {
        "apiKey": SPOONACULAR_API_KEY,
        "number": 10,
        "addRecipeInformation": True,
    }
    if user_profile:
        if user_profile.get("ingredients"):
            params["includeIngredients"] = user_profile["ingredients"]
        if user_profile.get("preferred_cuisine"):
            params["cuisine"] = user_profile["preferred_cuisine"]
        if isinstance(user_profile.get("avg_time"), int):
            params["maxReadyTime"] = user_profile["avg_time"]
    return params

def save_recipe_to_history(summary_ko, metadata={}):
    if not summary_ko.strip():
        print("ë¹ˆ ìš”ì•½. ì €ì¥ ìƒëµ")
        return

    try:
        # ë²¡í„° DBì— ì €ì¥
        db = get_or_create_vectorstore()
        existing = db.similarity_search(summary_ko, k=1)
        if existing and existing[0].page_content.strip() == summary_ko.strip():
            print(" ì´ë¯¸ ìœ ì‚¬í•œ ìš”ì•½ì´ ì €ì¥ë˜ì–´ ìˆìŒ. ìƒëµ")
            return

        metadata["saved_at"] = datetime.now().isoformat()
        doc = Document(page_content=summary_ko, metadata=metadata)
        db.add_documents([doc])
        db.save_local(VECTOR_DB_PATH)
        

        # DBì—ë„ ì €ì¥
        session = SessionLocal()
        
        model_columns = [column.name for column in UserHistory.__table__.columns]        
        ingredients_str = ""
        if metadata.get("ingredients"):
            if isinstance(metadata["ingredients"], list):
                ingredients_str = ", ".join(metadata["ingredients"])
            else:
                ingredients_str = str(metadata["ingredients"])
        
        cuisine_str = ""
        if metadata.get("cuisine"):
            if isinstance(metadata["cuisine"], list):
                cuisine_str = ", ".join(metadata["cuisine"])
            else:
                cuisine_str = str(metadata["cuisine"])
        
        history_data = {
            "user_id": "demo",
            "created_at": datetime.now()
        }
        
        if "summary" in model_columns:
            history_data["summary"] = summary_ko
        if "title" in model_columns:
            history_data["title"] = metadata.get("title", "")
        if "cuisine" in model_columns:
            history_data["cuisine"] = cuisine_str
        if "ingredients" in model_columns:
            history_data["ingredients"] = ingredients_str
        if "ready_in_minutes" in model_columns:
            history_data["ready_in_minutes"] = metadata.get("readyInMinutes", 0)
        
        # ìµœì¢… ê°ì²´ ìƒì„±
        history = UserHistory(**history_data)
        session.add(history)
        session.commit()
        session.close()
        print("âœ… DB ì €ì¥ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"ë ˆì‹œí”¼ ì €ì¥ ì‹¤íŒ¨: {e}")

        # ì„¸ì…˜ì´ ì—´ë ¤ìˆë‹¤ë©´ ë‹«ê¸°
        try:
            session.close()
        except:
            pass
        raise e

def find_similar_recipes(query_text, top_k=3):
    if not query_text.strip():
        return []
    db = get_or_create_vectorstore()
    retriever = db.as_retriever(search_kwargs={"k": top_k})
    return [doc.page_content for doc in retriever.get_relevant_documents(query_text)]

def summarize_recipe_in_korean(english_summary):
    prompt = f"""ë‹¤ìŒì€ ìš”ë¦¬ì— ëŒ€í•œ ì˜ì–´ ì„¤ëª…ì…ë‹ˆë‹¤. ì´ë¥¼ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\nì˜ì–´ ì„¤ëª…:\n{english_summary}\n\ní•œêµ­ì–´ ìš”ì•½:"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
        max_tokens=300,
    )
    return response.choices[0].message.content.strip()

def analyze_user_preferences(user_id="demo"):
    """ì‚¬ìš©ì ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ì„ í˜¸ë„ë¥¼ ë°˜í™˜"""
    db = SessionLocal()
    try:
        records = db.query(UserHistory).filter(UserHistory.user_id == user_id).all()
        
        ingredients, cuisines, times = [], [], []
        for r in records:
        
            if r.ingredients:
                ing_list = [ing.strip() for ing in r.ingredients.split(",") if ing.strip()]
                ingredients.extend(ing_list)
            
 
            if r.cuisine:
                cui_list = [cui.strip() for cui in r.cuisine.split(",") if cui.strip()]
                cuisines.extend(cui_list)

            if r.ready_in_minutes:
                times.append(r.ready_in_minutes)
        
        return {
            "top_ingredients": Counter(ingredients).most_common(5),
            "top_cuisines": Counter(cuisines).most_common(2),
            "avg_time": round(sum(times) / len(times), -1) if times else None
        }
    finally:
        db.close()

def build_personalized_recipe_params(user_id="demo"):
    prefs = analyze_user_preferences(user_id)
    params = {
        "apiKey": SPOONACULAR_API_KEY,
        "number": 1,
        "addRecipeInformation": True
    }
    if prefs["top_ingredients"]:
        params["includeIngredients"] = ",".join(i[0] for i in prefs["top_ingredients"])
    if prefs["top_cuisines"]:
        params["cuisine"] = prefs["top_cuisines"][0][0]
    if prefs["avg_time"] and prefs["avg_time"] < 40:
        params["maxReadyTime"] = int(prefs["avg_time"]) + 5
    return params

def generate_preference_summary(user_id="demo"):
    prefs = analyze_user_preferences(user_id)
    ing = ", ".join(i[0] for i in prefs["top_ingredients"]) or "íŠ¹ì • ì¬ë£Œ"
    cui = prefs["top_cuisines"][0][0] if prefs["top_cuisines"] else "íŠ¹ì • ìŠ¤íƒ€ì¼"
    time_desc = f"{int(prefs['avg_time'])}ë¶„ ë‚´ì™¸ì˜ ìš”ë¦¬ë¥¼ ì„ í˜¸í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì—¬ìš”." if prefs["avg_time"] else ""
    return f"ë‹¹ì‹ ì€ '{ing}' ì¬ë£Œë¥¼ ìì£¼ ì„ íƒí–ˆê³ , '{cui}' ìŠ¤íƒ€ì¼ ìš”ë¦¬ë¥¼ ì¢‹ì•„í•˜ë©°, {time_desc}".strip()

def generate_gpt_explanation(summary_ko, user_id="demo"):
    preference = generate_preference_summary(user_id)
    prompt = f"""ë‹¹ì‹ ì€ ê°œì¸í™”ëœ ìš”ë¦¬ ì¶”ì²œ AIì…ë‹ˆë‹¤.\n\në‹¤ìŒì€ ì‚¬ìš©ìì˜ ì·¨í–¥ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n\n{preference}\n\nì´ëŸ¬í•œ ì·¨í–¥ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ìš”ë¦¬ë¥¼ ì¶”ì²œí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤:\n\n{summary_ko}\n\nì´ ìš”ë¦¬ê°€ ì™œ ì¶”ì²œë˜ì—ˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. ë§ˆì¹˜ ìš”ë¦¬ íë ˆì´í„°ì²˜ëŸ¼ ë”°ëœ»í•˜ê²Œ ë§í•´ ì£¼ì„¸ìš”."""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8,
        max_tokens=300,
    )
    return response.choices[0].message.content.strip()